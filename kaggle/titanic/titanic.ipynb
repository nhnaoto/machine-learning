{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 訓練データの読み込み\n",
    "df = pd.read_csv(\"./input/train.csv\", header=0)\n",
    "\n",
    "# X : 説明変数列を取り出す\n",
    "# y : 目的変数列を取り出す\n",
    "X = df.loc[:, ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Embarked']];\n",
    "y = df.loc[:, ['Survived']]\n",
    "#print(X.dtypes)\n",
    "\n",
    "X['Title'] = df.Name.str.extract('([A-Za-z]+)\\.')\n",
    "X.Title.replace(['Mlle', 'Major', 'Lady', 'Sir', 'Jonkheer', 'Countess', 'Capt', 'Mme', 'Don', 'Dona'], ['other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other'],inplace=True)\n",
    "#print(X.Title.value_counts())\n",
    "\n",
    "# X : one hot encodeing\n",
    "ohe_columns = ['Sex','Embarked','Title']\n",
    "X = pd.get_dummies(X, columns=ohe_columns)\n",
    "X  = X.drop(['Title_other'], axis=1)\n",
    "\n",
    "#print(X.head(5))\n",
    "\n",
    "# X :欠損値補完\n",
    "from sklearn.preprocessing import Imputer\n",
    "#print(X.count())\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "X = pd.DataFrame(imp.transform(X), columns=X.columns.values)\n",
    "#print(X.count())\n",
    "\n",
    "# パイプライン作成 \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# pipe = Pipeline([('scl', StandardScaler()), ('est', GradientBoostingClassifier())])\n",
    "\n",
    "pipe_knn = Pipeline([('scl',StandardScaler()),('est',KNeighborsClassifier())])\n",
    "pipe_logistic = Pipeline([('scl',StandardScaler()),('est',LogisticRegression(random_state=1))])\n",
    "pipe_rf = Pipeline([('scl',StandardScaler()),('est',RandomForestClassifier(random_state=1))])\n",
    "pipe_gb = Pipeline([('scl',StandardScaler()),('est',GradientBoostingClassifier(random_state=1))])\n",
    "pipe_mlp = Pipeline([('scl',StandardScaler()),('est',MLPClassifier(hidden_layer_sizes=(100,3), max_iter=500, random_state=1))])\n",
    "\n",
    "pipe_names = ['KNN','Logistic','RandomForest','GradientBoosting','MLP']\n",
    "pipe_lines = [pipe_knn, pipe_logistic, pipe_rf, pipe_gb, pipe_mlp]\n",
    "\n",
    "# 交差検証\n",
    "from sklearn.model_selection import cross_val_score\n",
    "for (i,pipe) in enumerate(pipe_lines):\n",
    "    scores = cross_val_score(pipe, X, y.as_matrix().ravel(), cv=10, scoring='accuracy')\n",
    "    print('%s: %.3f'%(pipe_names[i],scores.mean()))\n",
    "\n",
    "# ->0.831\n",
    "pipe = pipe_gb\n",
    "\n",
    "# グリッドサーチ\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_gbc = {'est__n_estimators':[50,100],'est__subsample':[0.8, 1.0]}\n",
    "param = param_grid_gbc\n",
    "\n",
    "best_estimator = []\n",
    "print('----------------------------------------------------------------------------------------------')\n",
    "print('探索空間:%s' % param)\n",
    "gs = GridSearchCV(estimator=pipe, param_grid=param, scoring='accuracy', cv=3)\n",
    "gs = gs.fit(X, y.as_matrix().ravel())\n",
    "best_estimator.append(gs.best_estimator_) \n",
    "print('Best Score %.6f\\n' % gs.best_score_) \n",
    "print('Best Model: %s' % gs.best_estimator_)\n",
    "\n",
    "pipe_gb_best = Pipeline([('scl',StandardScaler()),('est',GradientBoostingClassifier(random_state=1, subsample=0.8, n_estimators=100))])\n",
    "pipe = pipe_gb_best\n",
    "\n",
    "\n",
    "#fit\n",
    "pipe.fit(X, y.as_matrix().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここから予測データ\n",
    "# 予測データの読み込み\n",
    "df = pd.read_csv(\"./input/test.csv\", header=0)\n",
    "\n",
    "# A ： 説明変数列を取り出す\n",
    "A = df.loc[:, ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Embarked']];\n",
    "#print(A.dtypes)\n",
    "\n",
    "A['Title']=df.Name.str.extract('([A-Za-z]+)\\.')\n",
    "A.Title.replace(['Mlle', 'Major', 'Lady', 'Sir', 'Jonkheer', 'Countess', 'Capt', 'Mme', 'Don', 'Dona'], ['other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other', 'other'],inplace=True)\n",
    "#print(A.Title.value_counts())\n",
    "\n",
    "# A : one hot encoding\n",
    "ohe_columns = ['Sex','Embarked','Title']\n",
    "A = pd.get_dummies(A, columns=ohe_columns)\n",
    "A  = A.drop(['Title_other'], axis=1)\n",
    "\n",
    "\n",
    "# A : の欠損値補完\n",
    "A = pd.DataFrame(imp.transform(A), columns=A.columns.values)\n",
    "\n",
    "# A : 予測\n",
    "pred = pipe.predict(A)\n",
    "\n",
    "# 予測結果ファイル出力\n",
    "B = df\n",
    "B[\"Survived\"] = pred\n",
    "B = df.loc[:, ['PassengerId', 'Survived']];\n",
    "B.to_csv(\"./output/prediction.csv\",index=False)\n",
    "\n",
    "# -> 0.78468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
